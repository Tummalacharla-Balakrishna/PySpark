{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75767a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83b0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('combineByKey').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41a80c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1, 2]), ('b', [1])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 2)])\n",
    "\n",
    "\"\"\"\n",
    "Generic function to combine the elements for each key using a custom set of aggregation functions.\n",
    "\n",
    "Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a “combined type” C.\n",
    "\n",
    "Users provide three functions:\n",
    "\n",
    "createCombiner, which turns a V into a C (e.g., creates a one-element list)\n",
    "\n",
    "mergeValue, to merge a V into a C (e.g., adds it to the end of a list)\n",
    "\n",
    "mergeCombiners, to combine two C’s into a single one (e.g., merges the lists)\n",
    "\n",
    "To avoid memory allocation, both mergeValue and mergeCombiners are allowed to modify and return their first argument instead of creating a new C.\n",
    "\n",
    "In addition, users can control the partitioning of the output RDD.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def combiner(a):\n",
    "    return [a]\n",
    "\n",
    "def mergeValue(a, b):\n",
    "    a.append(b)\n",
    "    \n",
    "    return a\n",
    "\n",
    "def mergeCombiner(a, b):\n",
    "    a.extend(b)\n",
    "    return a\n",
    "\n",
    "sorted(rdd.combineByKey(combiner, mergeValue, mergeCombiner).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62832f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', (15.0, 3)), ('B', (30.0, 2)), ('Z', (28.0, 4))]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "        ('A', 2.), ('A', 4.), ('A', 9.), \n",
    "        ('B', 10.), ('B', 20.), \n",
    "        ('Z', 3.), ('Z', 5.), ('Z', 8.), ('Z', 12.) \n",
    "       ]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize( data )\n",
    "\n",
    "sumCount = rdd.combineByKey(lambda value: (value, 1),\n",
    "                            lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                            lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
    "                           )\n",
    "sumCount.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afa73ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 15.0), ('B', 30.0), ('Z', 28.0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "        ('A', 2.), ('A', 4.), ('A', 9.), \n",
    "        ('B', 10.), ('B', 20.), \n",
    "        ('Z', 3.), ('Z', 5.), ('Z', 8.), ('Z', 12.) \n",
    "       ]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize( data )\n",
    "\n",
    "sumCount = rdd.combineByKey(lambda value: (value, 1),\n",
    "                            lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                            lambda x, y: (x[0] + y[0])\n",
    "                           )\n",
    "sumCount.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358021f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
