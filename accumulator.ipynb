{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3457b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abb048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA shared variable that can be accumulated, i.e., has a commutative and associative \\n“add” operation. Worker tasks on a Spark cluster can add values to an Accumulator\\nwith the += operator, but only the driver program is allowed to access its value,\\nusing value. Updates from the workers get propagated automatically to the driver program.\\n\\nWhile SparkContext supports accumulators for primitive data types like int \\nand float, users can also define accumulators for custom types by providing \\na custom AccumulatorParam object. Refer to its doctest for an example.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A shared variable that can be accumulated, i.e., has a commutative and associative \n",
    "“add” operation. Worker tasks on a Spark cluster can add values to an Accumulator\n",
    "with the += operator, but only the driver program is allowed to access its value,\n",
    "using value. Updates from the workers get propagated automatically to the driver program.\n",
    "\n",
    "While SparkContext supports accumulators for primitive data types like int \n",
    "and float, users can also define accumulators for custom types by providing \n",
    "a custom AccumulatorParam object. Refer to its doctest for an example.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab8b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created the spark session \n",
    "spark = SparkSession.builder.appName('Accumulator').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7cf12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#created the accumulator object that can be used for adding data\n",
    "#accumulator object has methods add and value\n",
    "#the accumulator is in sparkContext object\n",
    "\n",
    "acc = spark.sparkContext.accumulator(10)\n",
    "acc.add(50)\n",
    "acc.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94459f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = spark.sparkContext.accumulator(0)\n",
    "def accum(x):\n",
    "    z.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588c25a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spark.sparkContext.range(0,100)\n",
    "# data.collect()\n",
    "data.foreach(accum)\n",
    "z.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ebd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
