{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d045bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdfc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Date Methods').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "437351e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+--------------+----------+------------+\n",
      "|CustomerKey|Prefix|FirstName|LastName|BirthDate|MaritalStatus|Gender|        EmailAddress|AnnualIncome|EducationLevel|Occupation|   HomeOwner|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+--------------+----------+------------+\n",
      "|      11000|   MR.|      JON|    YANG| 4/8/1966|            M|     M|jon24@adventure-w...|    $90,000 |             2| Bachelors|Professional|\n",
      "|      11001|   MR.|   EUGENE|   HUANG|5/14/1965|            S|     M|eugene10@adventur...|    $60,000 |             3| Bachelors|Professional|\n",
      "|      11002|   MR.|    RUBEN|  TORRES|8/12/1965|            M|     M|ruben35@adventure...|    $60,000 |             3| Bachelors|Professional|\n",
      "|      11003|   MS.|  CHRISTY|     ZHU|2/15/1968|            S|     F|christy12@adventu...|    $70,000 |             0| Bachelors|Professional|\n",
      "|      11004|  MRS.|ELIZABETH| JOHNSON| 8/8/1968|            S|     F|elizabeth5@advent...|    $80,000 |             5| Bachelors|Professional|\n",
      "+-----------+------+---------+--------+---------+-------------+------+--------------------+------------+--------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('CustomerKey',StringType(),True),\n",
    "    StructField('Prefix',StringType(),True),\n",
    "    StructField('FirstName',StringType(),True),\n",
    "    StructField('LastName',StringType(),True),\n",
    "    StructField('BirthDate',StringType(),True),\n",
    "    StructField('MaritalStatus',StringType(),True),\n",
    "    StructField('Gender',StringType(),True),\n",
    "    StructField('EmailAddress',StringType(),True),\n",
    "    StructField('AnnualIncome',StringType(),True),\n",
    "    StructField('EducationLevel',StringType(),True),\n",
    "    StructField('Occupation',StringType(),True),\n",
    "    StructField('HomeOwner',StringType(),True),\n",
    "])\n",
    "\n",
    "customers = spark.read.option('header','true').csv('customers.csv',schema = schema)\n",
    "customers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10248fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|add_months(BirthDate, 1)|\n",
      "+------------------------+\n",
      "|              1966-05-08|\n",
      "|              1965-06-14|\n",
      "|              1965-09-12|\n",
      "|              1968-03-15|\n",
      "|              1968-09-08|\n",
      "|              1965-09-05|\n",
      "|              1964-06-09|\n",
      "|              1964-08-07|\n",
      "|              1964-05-01|\n",
      "|              1964-03-06|\n",
      "|              1963-12-04|\n",
      "|              1968-02-18|\n",
      "|              1968-09-06|\n",
      "|              1968-06-09|\n",
      "|              1979-03-27|\n",
      "|              1979-05-28|\n",
      "|              1944-07-26|\n",
      "|              1944-11-09|\n",
      "|              1978-04-07|\n",
      "|              1978-10-20|\n",
      "+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import add_months,date_format,col,udf\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "func = udf(lambda x : datetime.strptime(x,'%m/%d/%Y'),DateType())\n",
    "\n",
    "df = customers.withColumn('BirthDate',func(customers.BirthDate))\n",
    "df.select(add_months(df.BirthDate,1)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eede76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|dayofmonth(BirthDate)|\n",
      "+---------------------+\n",
      "|                    8|\n",
      "|                   14|\n",
      "|                   12|\n",
      "|                   15|\n",
      "|                    8|\n",
      "|                    5|\n",
      "|                    9|\n",
      "|                    7|\n",
      "|                    1|\n",
      "|                    6|\n",
      "|                    4|\n",
      "|                   18|\n",
      "|                    6|\n",
      "|                    9|\n",
      "|                   27|\n",
      "|                   28|\n",
      "|                   26|\n",
      "|                    9|\n",
      "|                    7|\n",
      "|                   20|\n",
      "+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dayofmonth\n",
    "df.select(dayofmonth(col('BirthDate'))).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
